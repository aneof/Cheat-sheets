{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pandas_memory_leak_tests.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEP2pa0ikTJlVzF0bRtkVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneof/Cheat-sheets/blob/master/Pandas_memory_leak_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOyQuS8LEefl"
      },
      "source": [
        "# A quick test for memory leaks when deleting or overwriting large dataframes after a column modification. It was mostly an issue in Google Cloud AI Platform Notebooks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMeSQA2mFZpO"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p__gJ4DVNti7"
      },
      "source": [
        "# Source for cleaning dataframe memory\n",
        "# https://stackoverflow.com/questions/39100971/how-do-i-release-memory-used-by-a-pandas-dataframe/49144260#49144260"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z97DCRQEUFV"
      },
      "source": [
        "# replace with large (>5gb) file of your choice\n",
        "in_df = pd.read_parquet('Data/CafeMedia/cafemedia_parquet/html/day=2021-01-26.parquet')\n",
        "print(in_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPgAGeduExc0"
      },
      "source": [
        "# test 1 (works as long as there is no editing)\n",
        "\n",
        "del in_df\n",
        "in_df=pd.DataFrame()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuy7IEABEyum"
      },
      "source": [
        "# test 2 (leaks 6gb on GCP)\n",
        "# there's probably a leftover reference that doesn't allow memory to be freed\n",
        "\n",
        "in_df['temp'] = in_df['html'].apply(lambda x: x[:1000])\n",
        "\n",
        "del in_df\n",
        "in_df=pd.DataFrame()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2wq68VtEzYH"
      },
      "source": [
        "# test 3 (leaks 6gb on GCP)\n",
        "\n",
        "htmls = list(in_df['html'].values)\n",
        "\n",
        "in_df['temp'] = [html[:1000] for html in htmls]\n",
        "\n",
        "del in_df\n",
        "in_df=pd.DataFrame()\n",
        "gc.collect()\n",
        "\n",
        "# FIX (colab)\n",
        "del htmls\n",
        "htmls = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4ogKnTFEz9H"
      },
      "source": [
        "# test 4 (leaks everything on GCP)\n",
        "\n",
        "htmls = list(in_df['html'].values)\n",
        "\n",
        "in_df['temp'] = [html[:1000] for html in htmls]\n",
        "\n",
        "del in_df['temp']\n",
        "del in_df\n",
        "in_df=pd.DataFrame()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlsIPzZXNfYu"
      },
      "source": [
        "# A way to list large objects\n",
        "import sys\n",
        "\n",
        "# These are the usual ipython objects, including this one you are creating\n",
        "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
        "\n",
        "# Get a sorted list of the objects and their sizes\n",
        "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-qGMJhdE5IY"
      },
      "source": [
        "# Garbage collection hotfix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdytQa3YE8Ob"
      },
      "source": [
        "# WARNING: THIS MAY BREAK PANDAS FUNCTIONALITY\n",
        "# DON'T USE IT IF PANDAS ERRORS ARE ENCOUNTERED AFTERWARDS\n",
        "\n",
        "# monkeypatches.py\n",
        "\n",
        "# Solving memory leak problem in pandas\n",
        "# https://github.com/pandas-dev/pandas/issues/2659#issuecomment-12021083\n",
        "# Basically overwrites how Pandas' __del__ works in CPython\n",
        "\n",
        "import pandas as pd\n",
        "from ctypes import cdll, CDLL\n",
        "import sys\n",
        "try:\n",
        "    cdll.LoadLibrary(\"libc.so.6\")\n",
        "    libc = CDLL(\"libc.so.6\")\n",
        "    libc.malloc_trim(0)\n",
        "except (OSError, AttributeError):\n",
        "    libc = None\n",
        "4\n",
        "__old_del = getattr(pd.DataFrame, '__del__', None)\n",
        "\n",
        "def __new_del(self):\n",
        "    if __old_del:\n",
        "        __old_del(self)\n",
        "    libc.malloc_trim(0)\n",
        "\n",
        "if libc:\n",
        "    print('Applying monkeypatch for pd.DataFrame.__del__', file=sys.stderr)\n",
        "    pd.DataFrame.__del__ = __new_del\n",
        "else:\n",
        "    print('Skipping monkeypatch for pd.DataFrame.__del__: libc or malloc_trim() not found', file=sys.stderr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcVg-1miE1OV"
      },
      "source": [
        "# test 5 (with garbage collection hotfix) (leaks everything on GCP)\n",
        "\n",
        "htmls = list(in_df['html'].values)\n",
        "\n",
        "in_df['temp'] = [html[:1000] for html in htmls]\n",
        "\n",
        "del in_df\n",
        "in_df=pd.DataFrame()\n",
        "gc.collect()\n",
        "del in_df\n",
        "in_df=pd.DataFrame()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n1IQA4IE2HJ"
      },
      "source": [
        "# test 6 (with garbage collection hotfix) (works great everywhere)\n",
        "# gc needs to be called twice on GCP for some reason. It clears half the memory\n",
        "# per call\n",
        "\n",
        "in_df['temp'] = in_df['html'].apply(lambda x: x[:1000])\n",
        "\n",
        "del in_df\n",
        "in_df=pd.DataFrame()\n",
        "gc.collect()\n",
        "del in_df\n",
        "in_df=pd.DataFrame()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}